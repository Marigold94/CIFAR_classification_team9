{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8be8653-7a6f-4bc3-9675-cbd44be6ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475517b2-d20e-46d2-a2be-d0d0abb5de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seed 생성입니다\n",
    "def set_seed(seed):\n",
    "    # Python random 시드 고정\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Numpy random 시드 고정\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # PyTorch random 시드 고정 (CPU)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # PyTorch random 시드 고정 (GPU)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # 모든 GPU에 동일한 시드 적용\n",
    "\n",
    "    # CUDNN deterministic 모드 사용 (비결정론적 연산 방지)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ad1035-d461-4a13-abb9-15e6ee7c3e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seed 사용입니다\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00ee3a32-c785-4142-8cb6-9e954d15dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-100 슈퍼클래스 정의\n",
    "superclasses = {\n",
    "    'aquatic_mammals': [4, 30, 55, 72, 95],\n",
    "    'fish': [1, 32, 67, 73, 91],\n",
    "    'flowers': [54, 62, 70, 82, 92],\n",
    "    'food_containers': [9, 10, 16, 28, 61],\n",
    "    'fruit_and_vegetables': [0, 51, 53, 57, 83],\n",
    "    'household_electrical_devices': [22, 39, 40, 86, 87],\n",
    "    'household_furniture': [5, 20, 25, 84, 94],\n",
    "    'insects': [6, 7, 14, 18, 24],\n",
    "    'large_carnivores': [3, 42, 43, 88, 97],\n",
    "    'large_man-made_outdoor_things': [12, 17, 37, 68, 76],\n",
    "    'large_natural_outdoor_scenes': [23, 33, 49, 60, 71],\n",
    "    'large_omnivores_and_herbivores': [15, 19, 21, 31, 38],\n",
    "    'medium_mammals': [34, 63, 64, 66, 75],\n",
    "    'non-insect_invertebrates': [26, 45, 77, 79, 99],\n",
    "    'people': [2, 11, 35, 46, 98],\n",
    "    'reptiles': [27, 29, 44, 78, 93],\n",
    "    'small_mammals': [36, 50, 65, 74, 80],\n",
    "    'trees': [47, 52, 56, 59, 96],\n",
    "    'vehicles_1': [8, 13, 48, 58, 90],\n",
    "    'vehicles_2': [41, 69, 81, 85, 89]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "684e347e-926f-45dc-918a-7b409f2e1302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping 구현\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac784bc1-ad53-42e9-9b25-b2882e9ec8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet 블록 정의 (Dropout 추가)\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, num_layers, dropout_rate=0.2):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(self._make_layer(in_channels + i * growth_rate, growth_rate, dropout_rate))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def _make_layer(self, in_channels, growth_rate, dropout_rate):\n",
    "        return nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, growth_rate, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.Dropout(p=dropout_rate)  # Dropout 추가\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.net:\n",
    "            out = layer(x)\n",
    "            x = torch.cat([x, out], 1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "911b9486-c84d-4db0-8d1c-9e6a02b2f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition Layer 정의\n",
    "class TransitionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(TransitionLayer, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.AvgPool2d(2, stride=2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2304c126-142c-4306-b40d-e4ecd566e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 수정: DenseNet의 복잡도 증가\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, growth_rate=48, num_blocks=5, num_layers_per_block=16, reduction=0.5, num_classes=100, dropout_rate=0.05):\n",
    "        super(DenseNet, self).__init__()\n",
    "        num_channels = 2 * growth_rate  # 초기 채널 수\n",
    "\n",
    "        # 초기 Convolution 레이어\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, num_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Dense Blocks와 Transition Layers 추가\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for i in range(num_blocks):\n",
    "            block = DenseBlock(num_channels, growth_rate, num_layers_per_block, dropout_rate)\n",
    "            self.blocks.append(block)\n",
    "            num_channels += growth_rate * num_layers_per_block\n",
    "            if i != num_blocks - 1:\n",
    "                transition = TransitionLayer(num_channels, int(num_channels * reduction))\n",
    "                self.blocks.append(transition)\n",
    "                num_channels = int(num_channels * reduction)\n",
    "        \n",
    "        # 최종 BatchNorm, ReLU 및 FC 레이어\n",
    "        self.bn = nn.BatchNorm2d(num_channels)\n",
    "        self.fc = nn.Linear(num_channels, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.bn(x)\n",
    "        x = torch.relu(x)\n",
    "        x = torch.mean(x, dim=[2, 3])  # Global Average Pooling\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79ef14a6-405c-41d5-9022-f7a791931da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet 초기화 함수\n",
    "def densenet_cifar(num_classes=100):\n",
    "    return DenseNet(growth_rate=32, num_blocks=3, num_layers_per_block=6, reduction=0.5, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f80ce100-d6c0-4fe9-bce6-45804ac8b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강 (Cutout, MixUp 추가)\n",
    "class Cutout(object):\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        h, w = img.size(1), img.size(2)\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "        \n",
    "        for _ in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "            \n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "            \n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "        \n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "        return img\n",
    "\n",
    "# 데이터 증강 (MixUp 비활성화 또는 alpha 값 조정)\n",
    "# MixUp을 처음에는 제거하여 학습 진행\n",
    "def mixup_data(x, y, alpha=0.4):  # alpha 값을 0.4로 낮춤\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cfb8276-5d01-49f4-b2fc-ae178f120778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강 수정 (Cutout 및 Random Erasing 확률 감소)\n",
    "# 데이터 증강 - AutoAugment 추가\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    AutoAugment(AutoAugmentPolicy.CIFAR10),  # AutoAugment 추가\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "    Cutout(n_holes=1, length=8),\n",
    "    transforms.RandomErasing(p=0.1)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fd81ab5-34c2-4216-b4f8-802c459c7a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 로드\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e778ffa-4ae3-4e51-b3b1-36bcc1982776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 수정: Dropout 비율 약간 증가, 학습률 조정\n",
    "model = DenseNet(num_classes=100, dropout_rate=0.2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1470310-a832-4bdc-b47d-6b7f4d5e62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 및 손실 함수 (학습률 및 weight_decay 조정)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=5e-5)  # 학습률 및 weight_decay 조정\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac98d512-be70-469b-b1d5-850799af6f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률 스케줄러 조정 - CosineAnnealingWarmRestarts\n",
    "scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-5)\n",
    "# ReduceLROnPlateau을 추가하여 학습률을 동적으로 감소시키기 위한 코드\n",
    "scheduler_plateau = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d3381e2-e522-499d-8b10-ed2a86ee1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping 추가\n",
    "early_stopping = EarlyStopping(patience=10, min_delta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e240a769-bef7-49c1-ba23-90031ad4058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 함수 (Top-1, Top-5, 평균 Superclass 정확도만 출력)\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct1 = 0\n",
    "    correct5 = 0\n",
    "    superclass_correct = {key: 0 for key in superclasses.keys()}\n",
    "    superclass_total = {key: 0 for key in superclasses.keys()}\n",
    "    \n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Top-1 정확도 계산\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct1 += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Top-5 정확도 계산\n",
    "            top5_prob, top5_pred = torch.topk(outputs, 5, dim=1)\n",
    "            correct5 += sum([1 if labels[i] in top5_pred[i] else 0 for i in range(len(labels))])\n",
    "\n",
    "            # Superclass 정확도 계산\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                for superclass, indices in superclasses.items():\n",
    "                    if label in indices:\n",
    "                        superclass_total[superclass] += 1\n",
    "                        if pred in indices:\n",
    "                            superclass_correct[superclass] += 1\n",
    "            \n",
    "            total += labels.size(0)\n",
    "\n",
    "    top1_acc = correct1 / total * 100\n",
    "    top5_acc = correct5 / total * 100\n",
    "    # 슈퍼클래스별 정확도의 평균 계산\n",
    "    superclass_acc = {key: (superclass_correct[key] / superclass_total[key]) * 100 if superclass_total[key] > 0 else 0 for key in superclasses.keys()}\n",
    "    average_superclass_acc = sum(superclass_acc.values()) / len(superclass_acc)  # 평균 슈퍼클래스 정확도\n",
    "\n",
    "    return top1_acc, top5_acc, average_superclass_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af0f678a-e874-4a56-8b9b-5baaeba79f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 평가 함수 (MixUp 제외)\n",
    "def train_and_evaluate(epochs):\n",
    "    epoch_list = []\n",
    "    train_acc_list = []\n",
    "    val_acc_list = []\n",
    "    top1_acc_list = []\n",
    "    top5_acc_list = []\n",
    "    avg_superclass_acc_list = []  # 평균 슈퍼클래스 정확도 리스트\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # MixUp 제거 후 일반 학습\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        \n",
    "        # Validation 및 정확도 평가\n",
    "        top1_acc, top5_acc, average_superclass_acc = evaluate_model(model, test_loader)\n",
    "\n",
    "        # 기록 저장\n",
    "        epoch_list.append(epoch + 1)\n",
    "        train_acc_list.append(train_acc)\n",
    "        val_acc_list.append(top1_acc)  # Top-1 정확도를 validation accuracy로 간주\n",
    "        top1_acc_list.append(top1_acc)\n",
    "        top5_acc_list.append(top5_acc)\n",
    "        avg_superclass_acc_list.append(average_superclass_acc)  # 평균 슈퍼클래스 정확도 저장\n",
    "        \n",
    "        # 학습률 스케줄러 스텝 (Plateau 기준)\n",
    "        scheduler_plateau.step(top1_acc)\n",
    "\n",
    "        # Early stopping 체크\n",
    "        early_stopping(-top1_acc)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        # 스코어 계산 및 출력\n",
    "        total_score = top1_acc + top5_acc + average_superclass_acc\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_acc:.2f}%, Val Accuracy (Top-1): {top1_acc:.2f}%\")\n",
    "        print(f\"Top-1 Accuracy: {top1_acc:.2f}% | Top-5 Accuracy: {top5_acc:.2f}% | Avg Superclass Accuracy: {average_superclass_acc:.2f}% | Total Score: {total_score:.2f}\")\n",
    "\n",
    "    return epoch_list, train_acc_list, val_acc_list, top1_acc_list, top5_acc_list, avg_superclass_acc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76fe38d9-4103-4e55-844b-31066417a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 코드 추가\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 정확도 시각화 (Train, Val, Top-1, Top-5)\n",
    "def plot_accuracies(epoch_list, train_acc_list, val_acc_list, top1_acc_list, top5_acc_list):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(epoch_list, train_acc_list, label='Train Accuracy')\n",
    "    plt.plot(epoch_list, val_acc_list, label='Validation Accuracy (Top-1)')\n",
    "    plt.plot(epoch_list, top1_acc_list, label='Top-1 Accuracy')\n",
    "    plt.plot(epoch_list, top5_acc_list, label='Top-5 Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy Metrics Over Epochs')\n",
    "    plt.show()\n",
    "\n",
    "# Superclass Accuracy 시각화\n",
    "def plot_superclass_accuracies(superclass_acc_list):\n",
    "    superclass_names = list(superclass_acc_list[0].keys())\n",
    "    superclass_accuracies = [superclass_acc_list[-1][key] for key in superclass_names]\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.bar(superclass_names, superclass_accuracies)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Superclass Accuracy at Final Epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ff6254-9dde-4b7c-9deb-1702079feb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200] - Loss: 4.0798, Train Accuracy: 7.97%, Val Accuracy (Top-1): 13.46%\n",
      "Top-1 Accuracy: 13.46% | Top-5 Accuracy: 38.42% | Avg Superclass Accuracy: 25.51% | Total Score: 77.39\n",
      "Epoch [2/200] - Loss: 3.5384, Train Accuracy: 16.36%, Val Accuracy (Top-1): 24.71%\n",
      "Top-1 Accuracy: 24.71% | Top-5 Accuracy: 55.27% | Avg Superclass Accuracy: 38.88% | Total Score: 118.86\n",
      "Epoch [3/200] - Loss: 3.1382, Train Accuracy: 23.39%, Val Accuracy (Top-1): 27.64%\n",
      "Top-1 Accuracy: 27.64% | Top-5 Accuracy: 59.34% | Avg Superclass Accuracy: 40.50% | Total Score: 127.48\n",
      "Epoch [4/200] - Loss: 2.8252, Train Accuracy: 29.44%, Val Accuracy (Top-1): 33.26%\n",
      "Top-1 Accuracy: 33.26% | Top-5 Accuracy: 64.74% | Avg Superclass Accuracy: 47.87% | Total Score: 145.87\n",
      "Epoch [5/200] - Loss: 2.5823, Train Accuracy: 34.21%, Val Accuracy (Top-1): 28.45%\n",
      "Top-1 Accuracy: 28.45% | Top-5 Accuracy: 55.55% | Avg Superclass Accuracy: 41.64% | Total Score: 125.64\n",
      "Epoch [6/200] - Loss: 2.3981, Train Accuracy: 37.62%, Val Accuracy (Top-1): 41.53%\n",
      "Top-1 Accuracy: 41.53% | Top-5 Accuracy: 72.90% | Avg Superclass Accuracy: 57.28% | Total Score: 171.71\n",
      "Epoch [7/200] - Loss: 2.2383, Train Accuracy: 41.43%, Val Accuracy (Top-1): 43.25%\n",
      "Top-1 Accuracy: 43.25% | Top-5 Accuracy: 75.07% | Avg Superclass Accuracy: 58.46% | Total Score: 176.78\n",
      "Epoch [8/200] - Loss: 2.1138, Train Accuracy: 44.11%, Val Accuracy (Top-1): 43.32%\n",
      "Top-1 Accuracy: 43.32% | Top-5 Accuracy: 74.84% | Avg Superclass Accuracy: 58.88% | Total Score: 177.04\n",
      "Epoch [9/200] - Loss: 1.9976, Train Accuracy: 46.54%, Val Accuracy (Top-1): 44.02%\n",
      "Top-1 Accuracy: 44.02% | Top-5 Accuracy: 75.15% | Avg Superclass Accuracy: 57.79% | Total Score: 176.96\n",
      "Epoch [10/200] - Loss: 1.9122, Train Accuracy: 48.57%, Val Accuracy (Top-1): 44.73%\n",
      "Top-1 Accuracy: 44.73% | Top-5 Accuracy: 76.21% | Avg Superclass Accuracy: 59.48% | Total Score: 180.42\n",
      "Epoch [11/200] - Loss: 1.8271, Train Accuracy: 50.54%, Val Accuracy (Top-1): 50.43%\n",
      "Top-1 Accuracy: 50.43% | Top-5 Accuracy: 80.53% | Avg Superclass Accuracy: 65.52% | Total Score: 196.48\n",
      "Epoch [12/200] - Loss: 1.7680, Train Accuracy: 51.81%, Val Accuracy (Top-1): 53.18%\n",
      "Top-1 Accuracy: 53.18% | Top-5 Accuracy: 81.90% | Avg Superclass Accuracy: 66.26% | Total Score: 201.34\n",
      "Epoch [13/200] - Loss: 1.7011, Train Accuracy: 53.91%, Val Accuracy (Top-1): 54.80%\n",
      "Top-1 Accuracy: 54.80% | Top-5 Accuracy: 84.14% | Avg Superclass Accuracy: 68.82% | Total Score: 207.76\n",
      "Epoch [14/200] - Loss: 1.6438, Train Accuracy: 55.15%, Val Accuracy (Top-1): 51.25%\n",
      "Top-1 Accuracy: 51.25% | Top-5 Accuracy: 80.70% | Avg Superclass Accuracy: 65.09% | Total Score: 197.04\n",
      "Epoch [15/200] - Loss: 1.5867, Train Accuracy: 56.26%, Val Accuracy (Top-1): 55.64%\n",
      "Top-1 Accuracy: 55.64% | Top-5 Accuracy: 83.64% | Avg Superclass Accuracy: 68.42% | Total Score: 207.70\n",
      "Epoch [16/200] - Loss: 1.5390, Train Accuracy: 57.30%, Val Accuracy (Top-1): 50.97%\n",
      "Top-1 Accuracy: 50.97% | Top-5 Accuracy: 79.78% | Avg Superclass Accuracy: 63.28% | Total Score: 194.03\n",
      "Epoch [17/200] - Loss: 1.4952, Train Accuracy: 58.40%, Val Accuracy (Top-1): 57.69%\n",
      "Top-1 Accuracy: 57.69% | Top-5 Accuracy: 85.64% | Avg Superclass Accuracy: 70.75% | Total Score: 214.08\n",
      "Epoch [18/200] - Loss: 1.4698, Train Accuracy: 59.24%, Val Accuracy (Top-1): 60.99%\n",
      "Top-1 Accuracy: 60.99% | Top-5 Accuracy: 86.79% | Avg Superclass Accuracy: 73.33% | Total Score: 221.11\n",
      "Epoch [19/200] - Loss: 1.4201, Train Accuracy: 60.50%, Val Accuracy (Top-1): 57.55%\n",
      "Top-1 Accuracy: 57.55% | Top-5 Accuracy: 85.08% | Avg Superclass Accuracy: 70.41% | Total Score: 213.04\n",
      "Epoch [20/200] - Loss: 1.3907, Train Accuracy: 61.20%, Val Accuracy (Top-1): 59.60%\n",
      "Top-1 Accuracy: 59.60% | Top-5 Accuracy: 86.53% | Avg Superclass Accuracy: 73.19% | Total Score: 219.32\n",
      "Epoch [21/200] - Loss: 1.3546, Train Accuracy: 62.19%, Val Accuracy (Top-1): 64.54%\n",
      "Top-1 Accuracy: 64.54% | Top-5 Accuracy: 89.94% | Avg Superclass Accuracy: 77.25% | Total Score: 231.73\n",
      "Epoch [22/200] - Loss: 1.3115, Train Accuracy: 63.27%, Val Accuracy (Top-1): 59.95%\n",
      "Top-1 Accuracy: 59.95% | Top-5 Accuracy: 87.49% | Avg Superclass Accuracy: 72.08% | Total Score: 219.52\n",
      "Epoch [23/200] - Loss: 1.2888, Train Accuracy: 63.78%, Val Accuracy (Top-1): 64.17%\n",
      "Top-1 Accuracy: 64.17% | Top-5 Accuracy: 89.33% | Avg Superclass Accuracy: 76.84% | Total Score: 230.34\n",
      "Epoch [24/200] - Loss: 1.2589, Train Accuracy: 64.49%, Val Accuracy (Top-1): 61.22%\n",
      "Top-1 Accuracy: 61.22% | Top-5 Accuracy: 86.80% | Avg Superclass Accuracy: 72.94% | Total Score: 220.96\n",
      "Epoch 00025: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch [25/200] - Loss: 1.2209, Train Accuracy: 65.42%, Val Accuracy (Top-1): 62.14%\n",
      "Top-1 Accuracy: 62.14% | Top-5 Accuracy: 87.44% | Avg Superclass Accuracy: 74.02% | Total Score: 223.60\n",
      "Epoch [26/200] - Loss: 1.0943, Train Accuracy: 68.90%, Val Accuracy (Top-1): 66.86%\n",
      "Top-1 Accuracy: 66.86% | Top-5 Accuracy: 90.78% | Avg Superclass Accuracy: 78.31% | Total Score: 235.95\n",
      "Epoch [27/200] - Loss: 1.0453, Train Accuracy: 70.21%, Val Accuracy (Top-1): 66.50%\n",
      "Top-1 Accuracy: 66.50% | Top-5 Accuracy: 90.54% | Avg Superclass Accuracy: 78.05% | Total Score: 235.09\n",
      "Epoch [28/200] - Loss: 1.0373, Train Accuracy: 70.35%, Val Accuracy (Top-1): 68.94%\n",
      "Top-1 Accuracy: 68.94% | Top-5 Accuracy: 91.95% | Avg Superclass Accuracy: 80.65% | Total Score: 241.54\n",
      "Epoch [29/200] - Loss: 1.0122, Train Accuracy: 71.22%, Val Accuracy (Top-1): 66.77%\n",
      "Top-1 Accuracy: 66.77% | Top-5 Accuracy: 90.08% | Avg Superclass Accuracy: 78.72% | Total Score: 235.57\n",
      "Epoch [30/200] - Loss: 0.9868, Train Accuracy: 71.86%, Val Accuracy (Top-1): 68.83%\n",
      "Top-1 Accuracy: 68.83% | Top-5 Accuracy: 91.52% | Avg Superclass Accuracy: 80.11% | Total Score: 240.46\n",
      "Epoch [31/200] - Loss: 0.9657, Train Accuracy: 72.41%, Val Accuracy (Top-1): 67.89%\n",
      "Top-1 Accuracy: 67.89% | Top-5 Accuracy: 91.26% | Avg Superclass Accuracy: 79.54% | Total Score: 238.69\n",
      "Epoch 00032: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch [32/200] - Loss: 0.9516, Train Accuracy: 72.85%, Val Accuracy (Top-1): 68.85%\n",
      "Top-1 Accuracy: 68.85% | Top-5 Accuracy: 91.44% | Avg Superclass Accuracy: 80.03% | Total Score: 240.32\n",
      "Epoch [33/200] - Loss: 0.8823, Train Accuracy: 74.80%, Val Accuracy (Top-1): 71.53%\n",
      "Top-1 Accuracy: 71.53% | Top-5 Accuracy: 92.64% | Avg Superclass Accuracy: 82.17% | Total Score: 246.34\n",
      "Epoch [34/200] - Loss: 0.8572, Train Accuracy: 75.25%, Val Accuracy (Top-1): 71.28%\n",
      "Top-1 Accuracy: 71.28% | Top-5 Accuracy: 92.48% | Avg Superclass Accuracy: 81.80% | Total Score: 245.56\n",
      "Epoch [35/200] - Loss: 0.8420, Train Accuracy: 75.98%, Val Accuracy (Top-1): 70.85%\n",
      "Top-1 Accuracy: 70.85% | Top-5 Accuracy: 92.49% | Avg Superclass Accuracy: 81.63% | Total Score: 244.97\n",
      "Epoch [36/200] - Loss: 0.8264, Train Accuracy: 76.27%, Val Accuracy (Top-1): 71.08%\n",
      "Top-1 Accuracy: 71.08% | Top-5 Accuracy: 92.72% | Avg Superclass Accuracy: 81.66% | Total Score: 245.46\n",
      "Epoch 00037: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Epoch [37/200] - Loss: 0.8256, Train Accuracy: 76.26%, Val Accuracy (Top-1): 71.48%\n",
      "Top-1 Accuracy: 71.48% | Top-5 Accuracy: 92.80% | Avg Superclass Accuracy: 81.93% | Total Score: 246.21\n",
      "Epoch [38/200] - Loss: 0.7859, Train Accuracy: 77.27%, Val Accuracy (Top-1): 71.46%\n",
      "Top-1 Accuracy: 71.46% | Top-5 Accuracy: 92.71% | Avg Superclass Accuracy: 81.89% | Total Score: 246.06\n",
      "Epoch [39/200] - Loss: 0.7709, Train Accuracy: 77.73%, Val Accuracy (Top-1): 72.41%\n",
      "Top-1 Accuracy: 72.41% | Top-5 Accuracy: 93.31% | Avg Superclass Accuracy: 82.78% | Total Score: 248.50\n",
      "Epoch [40/200] - Loss: 0.7631, Train Accuracy: 77.94%, Val Accuracy (Top-1): 72.56%\n",
      "Top-1 Accuracy: 72.56% | Top-5 Accuracy: 93.36% | Avg Superclass Accuracy: 82.79% | Total Score: 248.71\n",
      "Epoch [41/200] - Loss: 0.7630, Train Accuracy: 78.27%, Val Accuracy (Top-1): 72.48%\n",
      "Top-1 Accuracy: 72.48% | Top-5 Accuracy: 93.05% | Avg Superclass Accuracy: 82.80% | Total Score: 248.33\n",
      "Epoch [42/200] - Loss: 0.7511, Train Accuracy: 78.61%, Val Accuracy (Top-1): 72.13%\n",
      "Top-1 Accuracy: 72.13% | Top-5 Accuracy: 92.97% | Avg Superclass Accuracy: 82.77% | Total Score: 247.87\n",
      "Epoch [43/200] - Loss: 0.7438, Train Accuracy: 78.68%, Val Accuracy (Top-1): 72.46%\n",
      "Top-1 Accuracy: 72.46% | Top-5 Accuracy: 93.18% | Avg Superclass Accuracy: 82.80% | Total Score: 248.44\n",
      "Epoch 00044: reducing learning rate of group 0 to 6.2500e-06.\n",
      "Epoch [44/200] - Loss: 0.7363, Train Accuracy: 78.55%, Val Accuracy (Top-1): 72.17%\n",
      "Top-1 Accuracy: 72.17% | Top-5 Accuracy: 92.98% | Avg Superclass Accuracy: 82.52% | Total Score: 247.67\n",
      "Epoch [45/200] - Loss: 0.7214, Train Accuracy: 79.29%, Val Accuracy (Top-1): 72.32%\n",
      "Top-1 Accuracy: 72.32% | Top-5 Accuracy: 93.12% | Avg Superclass Accuracy: 82.85% | Total Score: 248.29\n",
      "Epoch [46/200] - Loss: 0.7079, Train Accuracy: 79.59%, Val Accuracy (Top-1): 72.15%\n",
      "Top-1 Accuracy: 72.15% | Top-5 Accuracy: 92.99% | Avg Superclass Accuracy: 82.58% | Total Score: 247.72\n",
      "Epoch [47/200] - Loss: 0.7094, Train Accuracy: 79.55%, Val Accuracy (Top-1): 72.77%\n",
      "Top-1 Accuracy: 72.77% | Top-5 Accuracy: 93.12% | Avg Superclass Accuracy: 83.11% | Total Score: 249.00\n",
      "Epoch [48/200] - Loss: 0.7053, Train Accuracy: 79.76%, Val Accuracy (Top-1): 71.95%\n",
      "Top-1 Accuracy: 71.95% | Top-5 Accuracy: 92.63% | Avg Superclass Accuracy: 82.36% | Total Score: 246.94\n",
      "Epoch [49/200] - Loss: 0.7123, Train Accuracy: 79.66%, Val Accuracy (Top-1): 72.87%\n",
      "Top-1 Accuracy: 72.87% | Top-5 Accuracy: 93.16% | Avg Superclass Accuracy: 83.26% | Total Score: 249.29\n"
     ]
    }
   ],
   "source": [
    "# 학습 실행\n",
    "epochs = 200\n",
    "epoch_list, train_acc_list, val_acc_list, top1_acc_list, top5_acc_list, avg_superclass_acc_list = train_and_evaluate(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23cc3f64-5e8d-44f8-a006-826d1ea5393e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epoch_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 시각화\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plot_accuracies(\u001b[43mepoch_list\u001b[49m, train_acc_list, val_acc_list, top1_acc_list, top5_acc_list)\n\u001b[1;32m      3\u001b[0m plot_superclass_accuracies(superclass_acc_list)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epoch_list' is not defined"
     ]
    }
   ],
   "source": [
    "# 정확도 시각화\n",
    "plot_accuracies(epoch_list, train_acc_list, val_acc_list, top1_acc_list, top5_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9852f86-c59c-4f09-8216-db5038267efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 슈퍼클래스 정확도 시각화\n",
    "def plot_avg_superclass_accuracies(avg_superclass_acc_list):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(range(1, len(avg_superclass_acc_list) + 1), avg_superclass_acc_list, label='Avg Superclass Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Avg Superclass Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.title('Average Superclass Accuracy Over Epochs')\n",
    "    plt.show()\n",
    "\n",
    "plot_avg_superclass_accuracies(avg_superclass_acc_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
